{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f2c264b",
   "metadata": {},
   "source": [
    "---\n",
    "ğŸ’¡ AdaBoost: í•µì‹¬ ì›ë¦¬ ìš”ì•½\n",
    "---\n",
    "\n",
    "AdaBoost(Adaptive Boosting)ëŠ” \n",
    "\n",
    "- 'ì•½í•œ í•™ìŠµê¸°(Weak Learner)'ë“¤ì„ `ìˆœì°¨ì ìœ¼ë¡œ í•™ìŠµ`ì‹œí‚¤ë©´ì„œ \n",
    "- `ì˜¤ë‹µì— ì§‘ì¤‘í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒ`ì‹œí‚¤ëŠ” ì•™ìƒë¸” ê¸°ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "1. ê°€ì¤‘ì¹˜ ì¡°ì • (Adaptive Weighting):\n",
    "\n",
    "     - ì²« ë²ˆì§¸ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³  ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "     - `ì˜¤ë‹µ(ì˜ëª» ì˜ˆì¸¡í•œ ë°ì´í„°)ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬`í•©ë‹ˆë‹¤.\n",
    "\n",
    "     - ì •ë‹µì— ëŒ€í•´ì„œëŠ” ê°€ì¤‘ì¹˜ë¥¼ ë‚®ì¶¥ë‹ˆë‹¤.\n",
    "\n",
    "    - ì´ë ‡ê²Œ ê°€ì¤‘ì¹˜ê°€ ì¡°ì •ëœ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ë‘ ë²ˆì§¸ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
    "\n",
    "    - ì´ ê³¼ì •ì„ ë°˜ë³µí•˜ë©°, `ë§¤ë²ˆ ì´ì „ ëª¨ë¸ì´ í‹€ë¦° ë¬¸ì œì— ë” ì§‘ì¤‘`í•˜ëŠ” ìƒˆë¡œìš´ ëª¨ë¸ì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "2. íˆ¬í‘œ ê°€ì¤‘ì¹˜ (Weighted Voting):\n",
    "\n",
    "    - ì´ë ‡ê²Œ ìˆœì°¨ì ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ëª¨ë“  ëª¨ë¸ë“¤ì´ ìµœì¢… ì˜ˆì¸¡ì„ ìœ„í•´ íˆ¬í‘œí•©ë‹ˆë‹¤.\n",
    "\n",
    "    - ì´ë•Œ, ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ ëª¨ë¸ì—ê²ŒëŠ” `ë” ë§ì€ íˆ¬í‘œê¶Œ(ê°€ì¤‘ì¹˜)ì„ ë¶€ì—¬`í•˜ì—¬ ìµœì¢… ê²°ê³¼ì— ë” í° ì˜í–¥ë ¥ì„ í–‰ì‚¬í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
    "\n",
    "    - ì„±ëŠ¥ì´ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì•˜ë˜ ëª¨ë¸ì€ íˆ¬í‘œê¶Œì´ ì ìŠµë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "ì´ ì›ë¦¬ë¥¼ í†µí•´ AdaBoostëŠ” `ì—¬ëŸ¬ ê°œì˜ ì•½í•œ ëª¨ë¸ì„ ê²°í•©`í•˜ì—¬ ê°•ë ¥í•˜ê³  ì •í™•í•œ 'í•˜ë‚˜ì˜ ëª¨ë¸'ì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    " \"`learning_rates`ëŠ” `ë‚®ê²Œ`, `n_estimators`ëŠ” `ë†’ê²Œ` ì¡°í•©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤\"\n",
    " \n",
    " ë¼ëŠ” ë¶€ë¶„ì´ ë°”ë¡œ ë¶€ìŠ¤íŒ… ëª¨ë¸ì„ íŠœë‹í•  ë•Œì˜ í•µì‹¬ ì›ë¦¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "* ì´ ì¡°í•©ì€ ëª¨ë¸ì´ ì˜¤ì°¨ë¥¼ ìˆ˜ì •í•˜ëŠ” ê³¼ì •ì„ ë‹¤ìŒê³¼ ê°™ì´ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "1. ë‚®ì€ learning_rate (ì‹ ì¤‘í•œ í•™ìŠµ): í•œ ë²ˆì˜ í•™ìŠµì—ì„œ ì˜¤ì°¨ë¥¼ í¬ê²Œ ìˆ˜ì •í•˜ì§€ ì•Šê³  ì¡°ê¸ˆì”©, ì‹ ì¤‘í•˜ê²Œ ë°°ìš°ê²Œ í•©ë‹ˆë‹¤.\n",
    "\n",
    "2. ë†’ì€ n_estimators (ì¶©ë¶„í•œ ë°˜ë³µ): ì˜¤ì°¨ë¥¼ ì‹ ì¤‘í•˜ê²Œ ìˆ˜ì •í•˜ëŠ” ê³¼ì •ì„ ì¶©ë¶„í•œ íšŸìˆ˜ë§Œí¼ ë°˜ë³µí•˜ê²Œ í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "ì™œ ì´ ì¡°í•©ì´ ìµœì ì¼ê¹Œ?\n",
    "\n",
    "ì´ ì¡°í•©ì€ ëª¨ë¸ì´ `ê³¼ì í•©(Overfitting)ì„ í”¼í•˜ë©´ì„œ`ë„ `ë³µì¡í•œ íŒ¨í„´ì„ ì •êµí•˜ê²Œ í•™ìŠµ`í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "* í˜„ì—…ì—ì„œ ë¶€ìŠ¤íŒ… ëª¨ë¸ì„ ì‚¬ìš©í•  ë•ŒëŠ” \n",
    "\n",
    "1. learning_rateëŠ” ë‚®ê²Œ ì„¤ì •í•˜ê³ , \n",
    "2. n_estimatorsëŠ” ë†’ê²Œ ì„¤ì •í•œ í›„ \n",
    "3. êµì°¨ ê²€ì¦(cross_val_score)ì„ í†µí•´ \n",
    "4. ìµœì ì˜ ì¡°í•©ì„ ì°¾ì•„ë‚´ëŠ” ì „ëµì´ \n",
    "5. ê°€ì¥ ë³´í¸ì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a825535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### AdaBoost ëª¨ë¸ í•™ìŠµ ë° ë¶„ì„ ì‹¤ìŠµ ì‹œì‘ ###\n",
      "\n",
      "--- AdaBoost ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ ë¹„êµ ì‹œì‘ ---\n",
      "\n",
      "(1) learning_rate=1.0, n_estimators=50 ëª¨ë¸ í•™ìŠµ ì¤‘...\n",
      "âœ… AdaBoost ëª¨ë¸ (ë†’ì€ í•™ìŠµë¥ , ë‹¨ìˆœí•œ íŠ¸ë¦¬) ì •í™•ë„: 0.7989\n",
      "\n",
      "(2) learning_rate=0.1, n_estimators=1000 ëª¨ë¸ í•™ìŠµ ì¤‘...\n",
      "âœ… AdaBoost ëª¨ë¸ (ë‚®ì€ í•™ìŠµë¥ , ë‹¨ìˆœí•œ íŠ¸ë¦¬) ì •í™•ë„: 0.7989\n",
      "\n",
      "(3) max_depth=5, learning_rate=0.1, n_estimators=1000 ëª¨ë¸ í•™ìŠµ ì¤‘...\n",
      "âœ… AdaBoost ëª¨ë¸ (ë‚®ì€ í•™ìŠµë¥ , ë³µì¡í•œ íŠ¸ë¦¬) ì •í™•ë„: 0.8156\n",
      "\n",
      "--- íŠ¹ì„± ì¤‘ìš”ë„(Feature Importance) í™•ì¸ ---\n",
      "ì „ì²˜ë¦¬ëœ íŠ¹ì„± ì´ë¦„: ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
      "íŠ¹ì„± ì¤‘ìš”ë„: [0.31661433 0.05797343 0.06979088 0.33199116 0.01551255 0.01444374\n",
      " 0.06335676 0.04183031 0.05930674 0.01853239 0.00051885 0.01012886]\n"
     ]
    }
   ],
   "source": [
    "# BOOT-09_AdaBoost_ì‹¤ìŠµ_í•´ë¶€.ipynb\n",
    "\n",
    "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"### AdaBoost ëª¨ë¸ í•™ìŠµ ë° ë¶„ì„ ì‹¤ìŠµ ì‹œì‘ ###\")\n",
    "\n",
    "# 2. ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "# íƒ€ì´íƒ€ë‹‰ í•™ìŠµ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "df_train = pd.read_csv('../../titanic_project/titanic_train.csv')\n",
    "\n",
    "# 3. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•˜ê³ , ëª¨ë¸ í•™ìŠµì— í•„ìš” ì—†ëŠ” íŠ¹ì„±ë“¤ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].mean())\n",
    "df_train['Embarked'] = df_train['Embarked'].fillna(df_train['Embarked'].mode()[0])\n",
    "df_train = df_train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, errors='ignore')\n",
    "\n",
    "# íŠ¹ì„±(X)ê³¼ ë ˆì´ë¸”(y) ë¶„ë¦¬\n",
    "X = df_train.drop('Survived', axis=1)\n",
    "y = df_train['Survived']\n",
    "\n",
    "# í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\n",
    "# ìˆ˜ì¹˜í˜• ë°ì´í„°ëŠ” í‘œì¤€ ìŠ¤ì¼€ì¼ë§ì„, ë²”ì£¼í˜• ë°ì´í„°ëŠ” ì›-í•« ì¸ì½”ë”©ì„ ì ìš©í•©ë‹ˆë‹¤.\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "numerical_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
    "\n",
    "print(\"\\n--- AdaBoost ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ ë¹„êµ ì‹œì‘ ---\")\n",
    "\n",
    "# 5. ì²« ë²ˆì§¸ AdaBoost ëª¨ë¸ (ë†’ì€ learning_rate, ë‚®ì€ n_estimators)\n",
    "# ì´ì „ ì‹¤ìŠµì—ì„œ ê°€ì¥ ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì¸ ì¡°í•©ì…ë‹ˆë‹¤.\n",
    "adaboost_model_high_lr_low_n = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1, random_state=42),\n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "adaboost_pipeline_high_lr_low_n = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                                  ('classifier', adaboost_model_high_lr_low_n)])\n",
    "\n",
    "print(\"\\n(1) learning_rate=1.0, n_estimators=50 ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "adaboost_pipeline_high_lr_low_n.fit(X_train, y_train)\n",
    "y_pred_high_lr_low_n = adaboost_pipeline_high_lr_low_n.predict(X_test)\n",
    "accuracy_high_lr_low_n = accuracy_score(y_test, y_pred_high_lr_low_n)\n",
    "print(f\"âœ… AdaBoost ëª¨ë¸ (ë†’ì€ í•™ìŠµë¥ , ë‹¨ìˆœí•œ íŠ¸ë¦¬) ì •í™•ë„: {accuracy_high_lr_low_n:.4f}\")\n",
    "\n",
    "\n",
    "# 6. ë‘ ë²ˆì§¸ AdaBoost ëª¨ë¸ (ë‚®ì€ learning_rate, ë†’ì€ n_estimators)\n",
    "# ì¼ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ë” ì¢‹ê²Œ ë‚˜ì˜¬ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë˜ëŠ” ì¡°í•©ì…ë‹ˆë‹¤.\n",
    "adaboost_model_low_lr_high_n = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1, random_state=42),\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "adaboost_pipeline_low_lr_high_n = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                                  ('classifier', adaboost_model_low_lr_high_n)])\n",
    "\n",
    "print(\"\\n(2) learning_rate=0.1, n_estimators=1000 ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "adaboost_pipeline_low_lr_high_n.fit(X_train, y_train)\n",
    "y_pred_low_lr_high_n = adaboost_pipeline_low_lr_high_n.predict(X_test)\n",
    "accuracy_low_lr_high_n = accuracy_score(y_test, y_pred_low_lr_high_n)\n",
    "print(f\"âœ… AdaBoost ëª¨ë¸ (ë‚®ì€ í•™ìŠµë¥ , ë‹¨ìˆœí•œ íŠ¸ë¦¬) ì •í™•ë„: {accuracy_low_lr_high_n:.4f}\")\n",
    "\n",
    "# 7. ì„¸ ë²ˆì§¸ AdaBoost ëª¨ë¸ (max_depthë¥¼ ë†’ì¸ ê²½ìš°)\n",
    "# ì•½í•œ í•™ìŠµê¸°ì˜ ë³µì¡ë„ë¥¼ 2ë¡œ ë†’ì—¬ì„œ ì„±ëŠ¥ ë³€í™”ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "adaboost_model_deeper = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=5, random_state=42), # max_depthë¥¼ 1 -> 5ë¡œ ë³€ê²½\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "adaboost_pipeline_deeper = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                           ('classifier', adaboost_model_deeper)])\n",
    "\n",
    "print(\"\\n(3) max_depth=5, learning_rate=0.1, n_estimators=1000 ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "adaboost_pipeline_deeper.fit(X_train, y_train)\n",
    "y_pred_deeper = adaboost_pipeline_deeper.predict(X_test)\n",
    "accuracy_deeper = accuracy_score(y_test, y_pred_deeper)\n",
    "print(f\"âœ… AdaBoost ëª¨ë¸ (ë‚®ì€ í•™ìŠµë¥ , ë³µì¡í•œ íŠ¸ë¦¬) ì •í™•ë„: {accuracy_deeper:.4f}\")\n",
    "\n",
    "\n",
    "# 8. ëª¨ë¸ì˜ ì¤‘ìš” íŠ¹ì§•(feature importances) í™•ì¸\n",
    "# ì „ì²˜ë¦¬ í›„ íŠ¹ì„± ì´ë¦„ë“¤ì„ ê°€ì ¸ì˜¤ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "# StandardScalerì™€ OneHotEncoderë¥¼ ê±°ì¹˜ë©´ì„œ ì›ë˜ íŠ¹ì„± ì´ë¦„ì´ ë°”ë€Œê³  ìƒˆë¡œìš´ íŠ¹ì„±ì´ ìƒê¸°ê¸° ë•Œë¬¸ì—\n",
    "# ëª¨ë“  íŠ¹ì„± ì´ë¦„ì„ ê²°í•©í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "print(\"\\n--- íŠ¹ì„± ì¤‘ìš”ë„(Feature Importance) í™•ì¸ ---\")\n",
    "# ì „ì²˜ë¦¬ëœ ìˆ«ìí˜• íŠ¹ì„± ì´ë¦„ ê°€ì ¸ì˜¤ê¸°\n",
    "numerical_feature_names = numerical_features\n",
    "\n",
    "# OneHotEncoderì˜ íŠ¹ì„± ì´ë¦„ ê°€ì ¸ì˜¤ê¸°\n",
    "onehot_encoded_names = adaboost_pipeline_deeper.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "\n",
    "# ëª¨ë“  íŠ¹ì„± ì´ë¦„ì„ ê²°í•©\n",
    "all_feature_names = list(numerical_feature_names) + list(onehot_encoded_names)\n",
    "\n",
    "feature_importances = adaboost_pipeline_deeper.named_steps['classifier'].feature_importances_\n",
    "print(\"ì „ì²˜ë¦¬ëœ íŠ¹ì„± ì´ë¦„:\", all_feature_names)\n",
    "print(\"íŠ¹ì„± ì¤‘ìš”ë„:\", feature_importances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl_env_250804",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
