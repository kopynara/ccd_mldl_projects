{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c4ff0bf",
   "metadata": {},
   "source": [
    "좋아! 지금 요청한 대로, VSCode나 Jupyter에서 바로 복사해 붙여넣기 좋은 **마크다운+표 형태**로 깔끔하게 정리해줄게 🤟\n",
    "이 파일은 `01_앙상블_기초_복습.ipynb`의 마크다운 셀에 들어가면 딱이야.\n",
    "\n",
    "---\n",
    "\n",
    "### 📚 01. 앙상블 기초 복습\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 앙상블 학습이란?\n",
    "\n",
    "여러 개의 \\*\\*약한 모델(weak learner)\\*\\*을 모아\n",
    "더 \\*\\*강력한 모델(strong learner)\\*\\*을 만드는 머신러닝 기법입니다.\n",
    "\n",
    "> **대표 기법**\n",
    ">\n",
    "> * `Bagging` : 모델을 병렬로 학습시켜 예측을 평균\n",
    "> * `Boosting` : 모델을 순차적으로 학습시켜 성능을 점점 개선\n",
    "> * `Stacking` : 여러 모델의 예측을 또 다른 모델에 넣어 학습\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 대표 앙상블 기법 요약\n",
    "\n",
    "| 기법명          | 핵심 아이디어                       | 대표 모델                       |\n",
    "| ------------ | ----------------------------- | --------------------------- |\n",
    "| **Bagging**  | 여러 모델을 **병렬로 학습**, 예측을 **평균** | 랜덤포레스트(Random Forest)       |\n",
    "| **Boosting** | 이전 모델의 오류를 **순차적으로 보완**       | GradientBoosting, XGBoost 등 |\n",
    "| **Stacking** | 여러 모델의 예측값을 **메타모델에 입력**      | 다양한 조합 가능                   |\n",
    "\n",
    "---\n",
    "\n",
    "원하면 이 부분 `.md` 파일로도 정리해서 넘겨줄 수 있어 😉\n",
    "다음으로 `결정트리 복습` 가자고 하면 바로 이어서 준비해줄게!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🤖 앙상블 기법 비교 실습: Bagging vs Boosting\n",
    "\n",
    "이 실습에서는 대표적인 앙상블 학습 기법인 **Bagging(Random Forest)** 과  \n",
    "**Boosting(Gradient Boosting)** 을 비교해볼 거예요.\n",
    "\n",
    "### 🧩 실험 시나리오\n",
    "\n",
    "- 동일한 데이터셋(`make_classification`) 사용\n",
    "- 같은 훈련/테스트 데이터\n",
    "- 같은 모델 수(`n_estimators=100`)\n",
    "- 다른 학습 방식 → 병렬 vs 순차\n",
    "\n",
    "### 🎯 비교 포인트\n",
    "\n",
    "| 항목        | Bagging                              | Boosting                                |\n",
    "|-------------|--------------------------------------|------------------------------------------|\n",
    "| 학습 방식   | 병렬 학습 (모델들을 동시에 학습)        | 순차 학습 (앞 모델 오류를 보완하며 학습)     |\n",
    "| 대표 모델   | 랜덤포레스트(RandomForest)           | 그레이디언트 부스팅(GradientBoosting)     |\n",
    "| 중점       | 분산 감소 → 과적합 방지                | 편향 감소 → 성능 점진적 향상              |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl_env_250804",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
