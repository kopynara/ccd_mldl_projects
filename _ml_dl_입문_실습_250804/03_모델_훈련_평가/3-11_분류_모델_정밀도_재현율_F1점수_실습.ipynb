{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d67d828",
   "metadata": {},
   "source": [
    "분류 모델 성능 평가 요약\n",
    "\n",
    "\n",
    "분류 모델의 성능을 평가하는 \n",
    "\n",
    "- **정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1-점수(F1-Score)**는 모두 \n",
    "\n",
    "- **'긍정(Positive)'**과 **'부정(Negative)'**이라는 개념을 기반으로 계산됩니다. \n",
    "\n",
    "- 여기서 '긍정(Positive)'은 우리가 찾고자 하는 ***목표***를 의미합니다.\n",
    "\n",
    "=======\n",
    "\n",
    "주요 평가 지표\n",
    "\n",
    "\n",
    "1. 정확도 (Accuracy)\n",
    "\n",
    "- 정의: 전체 예측 중 맞은 것의 비율\n",
    "\n",
    "- 특징: 가장 직관적이지만, 데이터가 불균형할 때 모델의 진짜 성능을 숨길 수 있습니다. \n",
    "\n",
    "       (예: 스팸 메일이 거의 없는 상황에서 모든 메일을 '정상'이라고 예측하면 정확도는 높게 나옴)\n",
    "\n",
    "\n",
    "2. 정밀도 (Precision)\n",
    "\n",
    "- 정의: 모델이 긍정이라고 예측한 것들 중 진짜 긍정인 비율 ( TP / TP+FP )\n",
    "\n",
    "- 특징: 모델이 얼마나 신중하게 예측했는지를 보여줍니다. 잘못된 긍정 예측(FP)을 줄이는 것이 중요할 때 사용합니다. \n",
    "\n",
    "       (예: \"암\" 오진을 피해야 할 때)\n",
    "\n",
    "\n",
    "3. 재현율 (Recall)\n",
    "\n",
    "- 정의: 실제 긍정인 것들 중 모델이 진짜 긍정이라고 찾아낸 비율 ( TP / TP+FN )\n",
    "\n",
    "- 특징: 모델이 중요한 것을 놓치지 않고 얼마나 잘 찾아냈는지를 보여줍니다. 진단을 놓치는 것(FN)을 피해야 할 때 중요합니다. \n",
    "     \n",
    "       (예: \"암\" 환자를 한 명이라도 놓치면 안 될 때)\n",
    "\n",
    "\n",
    "4. F1-점수 (F1-Score)\n",
    "\n",
    "- 정의: 정밀도와 재현율의 조화 평균\n",
    "\n",
    "- 특징: 정밀도와 재현율이 둘 다 중요하고 균형적인 성능을 원할 때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일명: 15_분류_모델_정밀도_재현율_F1점수_실습.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report # 새로운 평가 지표를 위한 라이브러리를 임포트합니다.\n",
    "import seaborn as sns\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. 환경 설정 및 라이브러리 설치 안내\n",
    "# -----------------------------------------------------------\n",
    "# 이 코드를 실행하기 위해 필요한 패키지를 설치하는 방법입니다.\n",
    "# 사용하시는 가상 환경 이름은 'mldl_env_250804'를 자동으로 사용합니다.\n",
    "# 터미널에서 다음 명령어를 실행하여 필요한 라이브러리를 설치하세요.\n",
    "# python3 -m pip install scikit-learn matplotlib numpy seaborn\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. 한글 폰트 설정\n",
    "# -----------------------------------------------------------\n",
    "# matplotlib에서 한글을 정상적으로 표시하기 위해 폰트를 설정합니다.\n",
    "# 'NanumGothic' 폰트가 설치되어 있지 않으면 경고가 발생할 수 있습니다.\n",
    "# 폰트가 없는 경우, 'NanumGothic'을 설치하거나 다른 한글 폰트 이름을 사용하세요.\n",
    "try:\n",
    "    font_path = fm.findfont(fm.FontProperties(family='NanumGothic'))\n",
    "    plt.rcParams['font.family'] = 'NanumGothic'\n",
    "    plt.rcParams['axes.unicode_minus'] = False # 마이너스 기호 깨짐 방지\n",
    "except:\n",
    "    print(\"경고: NanumGothic 폰트를 찾을 수 없습니다. 한글을 올바르게 표시하려면 한글 폰트를 설치하세요.\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. 데이터 준비\n",
    "# -----------------------------------------------------------\n",
    "# sklearn에서 제공하는 손글씨 숫자(digits) 데이터셋을 로드합니다.\n",
    "digits = load_digits()\n",
    "\n",
    "# 특성(X)과 타겟(y) 데이터를 분리합니다.\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4. 훈련 세트와 테스트 세트 분리\n",
    "# -----------------------------------------------------------\n",
    "# 데이터를 훈련 세트와 테스트 세트로 나눕니다. (80% 훈련, 20% 테스트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5. K-최근접 이웃(KNN) 모델 훈련\n",
    "# -----------------------------------------------------------\n",
    "# KNeighborsClassifier 모델을 생성합니다.\n",
    "# n_neighbors는 주변 몇 개의 이웃을 참고할지 설정하는 매개변수입니다. 여기서는 3개로 설정했습니다.\n",
    "# weights는 이웃의 투표에 가중치를 줄지 설정합니다. 'uniform'은 동일한 가중치를 부여합니다.\n",
    "model = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "\n",
    "# 훈련 세트로 모델을 학습시킵니다.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6. 모델 평가\n",
    "# -----------------------------------------------------------\n",
    "# predict()를 사용해 예측값 배열을 얻습니다.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 정확도(Accuracy)를 계산합니다.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n모델의 정확도: {accuracy:.4f}\")\n",
    "\n",
    "# 오차 행렬(Confusion Matrix)을 생성합니다.\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\n오차 행렬:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 7. 정밀도, 재현율, F1-점수 확인\n",
    "# -----------------------------------------------------------\n",
    "# classification_report를 사용하면 여러 평가지표를 한 번에 볼 수 있습니다.\n",
    "# 이 함수는 예측값(y_pred)과 실제값(y_test)을 인수로 받습니다.\n",
    "print(\"\\n모델의 상세 분류 리포트:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[str(i) for i in digits.target_names]))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 8. 오차 행렬 시각화\n",
    "# -----------------------------------------------------------\n",
    "# 오차 행렬을 히트맵(heatmap)으로 시각화하여 결과를 쉽게 파악할 수 있습니다.\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=digits.target_names, yticklabels=digits.target_names)\n",
    "plt.xlabel(\"예측된 값\")\n",
    "plt.ylabel(\"실제 값\")\n",
    "plt.title(\"K-최근접 이웃 오차 행렬\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
