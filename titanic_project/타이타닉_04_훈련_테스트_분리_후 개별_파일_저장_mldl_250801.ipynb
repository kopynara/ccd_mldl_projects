{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce16231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pclass        age  sibsp  parch     fare  adult_male  alone  sex_female  \\\n",
      "0         3  22.000000      1      0   7.2500        True  False         0.0   \n",
      "1         1  38.000000      1      0  71.2833       False  False         1.0   \n",
      "2         3  26.000000      0      0   7.9250       False   True         1.0   \n",
      "3         1  35.000000      1      0  53.1000       False  False         1.0   \n",
      "4         3  35.000000      0      0   8.0500        True   True         0.0   \n",
      "..      ...        ...    ...    ...      ...         ...    ...         ...   \n",
      "886       2  27.000000      0      0  13.0000        True   True         0.0   \n",
      "887       1  19.000000      0      0  30.0000       False   True         1.0   \n",
      "888       3  29.699118      1      2  23.4500       False  False         1.0   \n",
      "889       1  26.000000      0      0  30.0000        True   True         0.0   \n",
      "890       3  32.000000      0      0   7.7500        True   True         0.0   \n",
      "\n",
      "     sex_male  embarked_C  embarked_Q  embarked_S  class_First  class_Second  \\\n",
      "0         1.0         0.0         0.0         1.0          0.0           0.0   \n",
      "1         0.0         1.0         0.0         0.0          1.0           0.0   \n",
      "2         0.0         0.0         0.0         1.0          0.0           0.0   \n",
      "3         0.0         0.0         0.0         1.0          1.0           0.0   \n",
      "4         1.0         0.0         0.0         1.0          0.0           0.0   \n",
      "..        ...         ...         ...         ...          ...           ...   \n",
      "886       1.0         0.0         0.0         1.0          0.0           1.0   \n",
      "887       0.0         0.0         0.0         1.0          1.0           0.0   \n",
      "888       0.0         0.0         0.0         1.0          0.0           0.0   \n",
      "889       1.0         1.0         0.0         0.0          1.0           0.0   \n",
      "890       1.0         0.0         1.0         0.0          0.0           0.0   \n",
      "\n",
      "     class_Third  who_child  who_man  who_woman  survived  \n",
      "0            1.0        0.0      1.0        0.0         0  \n",
      "1            0.0        0.0      0.0        1.0         1  \n",
      "2            1.0        0.0      0.0        1.0         1  \n",
      "3            0.0        0.0      0.0        1.0         1  \n",
      "4            1.0        0.0      1.0        0.0         0  \n",
      "..           ...        ...      ...        ...       ...  \n",
      "886          0.0        0.0      1.0        0.0         0  \n",
      "887          0.0        0.0      0.0        1.0         1  \n",
      "888          1.0        0.0      0.0        1.0         0  \n",
      "889          0.0        0.0      1.0        0.0         1  \n",
      "890          1.0        0.0      1.0        0.0         0  \n",
      "\n",
      "[891 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. 전처리된 CSV 파일 불러오기 ---\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 분리 완료된 CSV 파일을 불러옵니다.\n",
    "\n",
    "df = pd.read_csv('타이타닉_분리완료_mldl_250801.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14fcefaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터의 행 개수: 891\n",
      "y 데이터의 행 개수: 891\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 2. 특성(X)과 타겟(y) 분리 ---\n",
    "# 불러온 DataFrame에서 특성(X)과 타겟(y)을 다시 분리합니다.\n",
    "\n",
    "y = df['survived']\n",
    "X = df.drop('survived', axis=1)\n",
    "\n",
    "# X와 y의 행 개수(크기) 확인\n",
    "# X.shape는 (행, 열) 형태의 튜플을 반환하고, X.shape[0]은 그중 첫 번째 값인 행 개수를 가져와.\n",
    "\n",
    "print(f\"X 데이터의 행 개수: {X.shape[0]}\")\n",
    "print(f\"y 데이터의 행 개수: {y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "febbbc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 3. 훈련/테스트 데이터 분리 ---\n",
    "\n",
    "# # - train_test_split() 함수를 사용해 X와 y를 훈련용(train)과 테스트용(test)으로 나눕니다.\n",
    "# # - test_size=0.2: 전체 데이터 중 20%를 테스트 데이터로 사용하겠다는 의미입니다.\n",
    "# # - random_state: 데이터를 나눌 때 무작위성을 제어합니다. 이 값을 지정해야 나중에 다시 실행해도 똑같은 결과가 나옵니다.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d6b0a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 훈련/테스트 데이터 분리 완료, 크기 확인. ---\n",
      "X_train 훈련 데이터 크기: 712 행\n",
      "X_test 테스트 데이터 크기: 179 행\n",
      "y_train 훈련 데이터 크기: 712 행\n",
      "y_test 테스트 데이터 크기: 179 행\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4. 분리 결과 확인 ---\n",
    "\n",
    "# 분리된 데이터의 크기를 확인합니다.\n",
    "# 891의 20%는 178.2인데, train_test_split가 자동으로 반올림해서 테스트 데이터는 179개로 나뉠 거야.\n",
    "# 남은 712개(891 - 179)가 훈련 데이터가 되겠지.\n",
    "\n",
    "print(\"--- 훈련/테스트 데이터 분리 완료, 크기 확인. ---\")\n",
    "print(f\"X_train 훈련 데이터 크기: {X_train.shape[0]} 행\")\n",
    "print(f\"X_test 테스트 데이터 크기: {X_test.shape[0]} 행\")\n",
    "print(f\"y_train 훈련 데이터 크기: {y_train.shape[0]} 행\")\n",
    "print(f\"y_test 테스트 데이터 크기: {y_test.shape[0]} 행\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35915492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 훈련/테스트 데이터가 CSV 파일로 성공적으로 저장되었습니다. ---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. 분리된 데이터 저장 ---\n",
    "# 훈련용, 테스트용 데이터를 각각의 CSV 파일로 저장합니다.\n",
    "\n",
    "# # - *****중요****** 왜 이전 단계에서는 합친 후 저장하고 지금 단계에서는 나뉘어진 여러 파일로 저장할까?\n",
    "\n",
    "# # - (단계 4: 특성(X)과 타겟(y) 분리 완료 후) 이 단계에서는 '문제(X)'와 '정답(y)'을 합쳐서 관리하는 것이 편리했습니다. \n",
    "# # - (단계 5: 훈련/테스트 분리 후) 하지만 지금은 train_test_split() 함수에 의해 데이터가 무작위로 나뉘어 역할이 정해졌습니다.\n",
    "\n",
    "# # - 훈련 데이터로만 학습시키고 테스트 데이터로는 평가해야 하는데, 데이터를 하나로 합쳐 저장하면 훈련용/테스트용 구분이 사라집니다.\n",
    "\n",
    "# # - 이렇게 되면 모델이 학습할 때 보지 말아야 할 테스트 데이터를 보게 되어, '컨닝'을 하게 되고 평가 결과가 왜곡될 수 있습니다.\n",
    "# # - 따라서 이 상태를 그대로 보존해야 모델을 정확하게 학습하고 평가할 수 있기 때문에, 각각 따로 저장하는 것이 안전하고 효율적입니다.\n",
    "\n",
    "# # - index=False를 사용해 인덱스를 불필요하게 저장하지 않습니다.\n",
    "\n",
    "\n",
    "# 훈련 데이터 저장\n",
    "\n",
    "X_train.to_csv('타이타닉_X_train_mldl_250801.csv', index=False)\n",
    "y_train.to_csv('타이타닉_y_train_mldl_250801.csv', index=False)\n",
    "\n",
    "X_train.to_csv('타이타닉_X_train_mldl_250801.csv', index=False)\n",
    "y_train.to_csv('타이타닉_y_train_mldl_250801.csv', index=False)\n",
    "\n",
    "\n",
    "# 테스트 데이터 저장\n",
    "\n",
    "X_test.to_csv('타이타닉_X_test_mldl_250801.csv', index=False)\n",
    "y_test.to_csv('타이타닉_y_test_mldl_250801.csv', index=False)\n",
    "\n",
    "print(\"--- 훈련/테스트 데이터가 CSV 파일로 성공적으로 저장되었습니다. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl250801",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
