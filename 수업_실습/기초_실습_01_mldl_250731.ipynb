{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f534710e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris 데이터셋 로드 완료.\n",
      "\n",
      "--- 데이터 정보 ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "\n",
      "--- 데이터 미리보기 (상위 5개 행) ---\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 0단계: Iris 데이터셋 로드\n",
    "# seaborn에 내장된 iris 데이터셋을 불러옵니다.\n",
    "\n",
    "df = sns.load_dataset('iris')\n",
    "\n",
    "print(\"Iris 데이터셋 로드 완료.\")\n",
    "print(\"\\n--- 데이터 정보 ---\")\n",
    "\n",
    "df.info()\n",
    "\n",
    "print(\"\\n--- 데이터 미리보기 (상위 5개 행) ---\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6acf06",
   "metadata": {},
   "source": [
    "1. df.info() 출력 결과 해석\n",
    "\n",
    "--- 데이터 정보 ---\n",
    "<class 'pandas.core.frame.DataFrame'> # 이건 '판다스 데이터프레임'이라는 데이터 형식이라는 뜻\n",
    "RangeIndex: 150 entries, 0 to 149 # 데이터가 총 150개 (행), 인덱스는 0번부터 149번까지 있다는 뜻\n",
    "\n",
    "Data columns (total 5 columns): # 데이터에 총 5개의 '컬럼(열)'이 있다는 뜻\n",
    " #   Column        Non-Null Count  Dtype  # 각 컬럼의 이름, 비어있지 않은 값의 개수, 데이터 타입\n",
    " ---  ------        --------------  -----\n",
    "  0   sepal_length  150 non-null    float64 # 'sepal_length' 컬럼은 150개 값이 비어있지 않고, 숫자(소수점 포함) 타입\n",
    "  1   sepal_width   150 non-null    float64 # 'sepal_width' 컬럼은 150개 값이 비어있지 않고, 숫자(소수점 포함) 타입\n",
    "  2   petal_length  150 non-null    float64 # 'petal_length' 컬럼은 150개 값이 비어있지 않고, 숫자(소수점 포함) 타입\n",
    "  3   petal_width   150 non-null    float64 # 'petal_width' 컬럼은 150개 값이 비어있지 않고, 숫자(소수점 포함) 타입\n",
    "  4   species       150 non-null    object  # 'species' 컬럼은 150개 값이 비어있지 않고, '글자' 타입 (문자열)\n",
    "\n",
    "dtypes: float64(4), object(1) # 전체 5개 컬럼 중 숫자(float64) 4개, 글자(object) 1개라는 뜻\n",
    "memory usage: 6.0+ KB # 이 데이터가 컴퓨터 메모리를 약 6.0 킬로바이트 사용하고 있다는 뜻 (크게 중요하지 않아요)\n",
    "\n",
    "\n",
    "2. Non-Null Count가 150 non-null인 의미\n",
    "Non-Null Count는 '비어있지 않은(Not Empty)' 값의 개수를 의미합니다.\n",
    "\n",
    "150 non-null이라는 것은 해당 컬럼의 모든 150개 데이터가 비어있지 않고(즉, 결측치 없이), 꽉 채워져 있다는 뜻입니다.\n",
    "\n",
    "만약 sepal_length가 148 non-null이었다면, 총 150개 데이터 중 2개가 비어있다는 의미가 됩니다.\n",
    "\n",
    "\n",
    "3. species 컬럼의 다른 값 확인 방법\n",
    "df.head()는 데이터의 상위 5개 행만 보여주기 때문에, species 컬럼에 'setosa'만 보였을 겁니다. \n",
    "Iris 데이터셋은 각 종이 50개씩 순서대로 배열되어 있는 경우가 많아서, 처음 5개는 모두 'setosa'일 가능성이 높아요.\n",
    "\n",
    "모든 species 종류를 확인하려면 다음 코드를 사용하면 됩니다.\n",
    "\n",
    "Python\n",
    "\n",
    "# 'species' 컬럼에 어떤 고유한 값들이 있는지 확인\n",
    "print(df['species'].unique())\n",
    "이 코드를 실행하면 ['setosa' 'versicolor' 'virginica'] 이렇게 세 가지 종류가 모두 출력될 것입니다.\n",
    "\n",
    "\n",
    "4. 범주형 특성 인코딩이란?\n",
    "쉽게 설명: 컴퓨터(머신러닝 모델)는 setosa, versicolor, virginica 같은 글자(텍스트)를 직접 이해하지 못해요. \n",
    "컴퓨터는 모든 것을 숫자로 바꿔야만 계산하고 학습할 수 있습니다.\n",
    "\n",
    "목적: 그래서 'setosa'라는 글자를 0이라는 숫자로, 'versicolor'를 1이라는 숫자로, \n",
    "     'virginica'를 2라는 숫자로 변환해 주는 과정을 '범주형 특성 인코딩'이라고 합니다.\n",
    "\n",
    "'범주형'이라는 말의 의미: '남자/여자', 'A등급/B등급/C등급', 'setosa/versicolor/virginica'처럼, 정해진 몇 가지 종류(카테고리) 중 \n",
    "                        하나에 속하는 데이터를 '범주형' 데이터라고 부릅니다. 이런 데이터를 숫자로 바꿔주는 것이죠.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8fb87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# 'species' 컬럼에 어떤 고유한 값들이 있는지 확인\n",
    "print(df['species'].unique())\n",
    "# 이 코드를 실행하면 ['setosa' 'versicolor' 'virginica'] 이렇게 세 가지 종류가 모두 출력될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d15047",
   "metadata": {},
   "source": [
    "7단계 공식 중 단계 1.2: 범주형 특성 인코딩의 핵심 코드를 실행하여, \n",
    "텍스트 형태의 'species' 컬럼을 머신러닝 모델이 이해할 수 있는 숫자 형태로 변환해야 합니다.\n",
    "이 코드를 입력하고 실행해 보세요.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### **LabelEncoder 코드 해부 (핵심 요약)**\n",
    "\n",
    "머신러닝 모델은 **숫자만 이해**하므로, `setosa`, `versicolor` 같은 **글자(범주형 데이터)**를 `0, 1, 2`와 같은 **숫자(레이블)**로 변환해야 합니다. 이때 `LabelEncoder` 도구를 사용해요.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. `le_species = LabelEncoder()`\n",
    "* **의미**: 글자를 숫자로 바꿔주는 **`LabelEncoder` 도구**를 **`le_species`라는 이름으로 준비**하는 단계. (아직 아무것도 변환하지 않고, 도구만 준비하는 것)\n",
    "* **이유**: 이 도구가 나중에 **학습된 변환 규칙을 기억**하고 있어야 재사용하거나 역변환할 수 있기 때문.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. `df['species_encoded'] = le_species.fit_transform(df['species'])`\n",
    "* **의미**:\n",
    "    1.  `le_species.fit_transform(df['species'])`: `le_species` 도구가 `df['species']` 컬럼의 **글자들(setosa, versicolor, virginica)을 학습**하여 (`fit`) 어떤 숫자로 바꿀지 규칙을 정하고, 그 규칙대로 **글자들을 숫자로 변환** (`transform`)합니다.\n",
    "        * (예: setosa → 0, versicolor → 1, virginica → 2)\n",
    "    2.  `df['species_encoded'] = ...`: 변환된 숫자 목록을 `df` 데이터프레임의 **새로운 컬럼인 `species_encoded`에 저장**합니다.\n",
    "* **결과**: `df`에 `species_encoded`라는 숫자 컬럼이 추가됨.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. `for i, name in enumerate(le_species.classes_): print(f\"{name} --> {i}\")`\n",
    "* **의미**: `le_species` 도구가 **어떤 글자를 어떤 숫자로 변환했는지 (학습된 규칙)**를 확인하는 코드.\n",
    "* **`le_species.classes_`**: `le_species` 도구가 기억하는 원본 글자 목록.\n",
    "* **`enumerate()`**: 목록의 값과 그 값의 순서 번호(인덱스)를 함께 꺼내주는 기능.\n",
    "* **결과**: `setosa --> 0`, `versicolor --> 1`, `virginica --> 2` 와 같이 화면에 출력됨. (변환 규칙 확인)\n",
    "* ** (뒤에 _가 붙은 것은 보통 '학습 후에 생성된' 속성을 의미해요.)\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. `df[['species', 'species_encoded']].head()`\n",
    "* **의미**: **변환 전의 `species` 컬럼과 변환 후의 `species_encoded` 컬럼을 나란히 보여주어**, 실제로 숫자로 잘 변환되었는지 눈으로 직접 확인하는 코드.\n",
    "* **`[[...]]`**: 여러 개의 컬럼을 선택할 때 사용하는 문법.\n",
    "* **`.head()`**: 데이터의 맨 위 5개 행만 보여줌.\n",
    "* **[['species', 'species_encoded']]:\n",
    "\n",
    "뜻: 대괄호가 두 개 겹쳐 있죠? 이건 '컬럼 여러 개'를 선택하겠다는 의미예요. \n",
    "여기서는 species 컬럼과 species_encoded 컬럼을 둘 다 선택하라는 뜻입니다. \n",
    "(하나만 선택할 때는 df['컬럼이름']처럼 대괄호가 하나죠.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d0e00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'species' 컬럼 인코딩 완료.\n",
      "변환된 타겟 클래스 (원본 텍스트 --> 인코딩된 숫자):\n",
      "setosa --> 0\n",
      "versicolor --> 1\n",
      "virginica --> 2\n",
      "\n",
      "데이터 미리보기 (인코딩된 'species_encoded' 컬럼 포함):\n",
      "  species  species_encoded\n",
      "0  setosa                0\n",
      "1  setosa                0\n",
      "2  setosa                0\n",
      "3  setosa                0\n",
      "4  setosa                0\n"
     ]
    }
   ],
   "source": [
    "# 1.2 범주형 특성 인코딩 (타겟 'species' 컬럼을 숫자로 변환)\n",
    "# LabelEncoder를 사용하여 'species'를 숫자로 변환합니다.\n",
    "\n",
    "le_species = LabelEncoder()\n",
    "df['species_encoded'] = le_species.fit_transform(df['species'])\n",
    "\n",
    "print(\"\\n'species' 컬럼 인코딩 완료.\")\n",
    "print(\"변환된 타겟 클래스 (원본 텍스트 --> 인코딩된 숫자):\")\n",
    "\n",
    "# 어떤 숫자가 어떤 붓꽃 종류를 의미하는지 확인 (중요!)\n",
    "\n",
    "for i, name in enumerate(le_species.classes_):\n",
    "    print(f\"{name} --> {i}\")\n",
    "\n",
    "print(\"\\n데이터 미리보기 (인코딩된 'species_encoded' 컬럼 포함):\")\n",
    "print(df[['species', 'species_encoded']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243ac5c",
   "metadata": {},
   "source": [
    "굿모닝! LabelEncoder 개념을 마크다운으로 깔끔하게 정리하셨군요. 아주 잘하셨습니다!\n",
    "\n",
    "이제 7단계 공식의 다음 단계인 특성과 타겟 분리 및 데이터 분할을 진행해 봅시다.\n",
    "\n",
    "[목표] Iris (붓꽃) 데이터셋으로 '붓꽃의 종류' 예측하기\n",
    "단계 2: 특성과 타겟 분리 및 데이터 분할\n",
    "이 단계에서는 모델 학습에 사용할 입력 데이터(X, 특성)와 예측하려는 결과(y, 타겟)를 분리하고, 이 데이터들을 훈련용(X_train, y_train)과 테스트용(X_test, y_test)으로 나눌 거예요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78aec09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성(X)과 타겟(y) 분리 완료.\n",
      "\n",
      "X (특성) 컬럼: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "y (타겟) 데이터 미리보기 (첫 5개): [0, 0, 0, 0, 0]\n",
      "\n",
      "데이터 분할 완료.\n",
      "훈련 데이터 X_train 크기 : (120, 4)\n",
      "예측 데이터 X_test 크기 : (30, 4)\n"
     ]
    }
   ],
   "source": [
    "# 2.1 특성(X)과 타겟(y) 분리\n",
    "# X (특성): 붓꽃의 특징들 (꽃받침/꽃잎 길이, 너비)\n",
    "# y (타겟): 우리가 예측하려는 붓꽃의 종류 (숫자로 인코딩된 컬럼)\n",
    "\n",
    "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = df['species_encoded'] # 이미 LabelEncoder로 숫자로 변환된 타겟 컬럼 사용\n",
    "\n",
    "print(\"특성(X)과 타겟(y) 분리 완료.\")\n",
    "print(\"\\nX (특성) 컬럼:\", X.columns.tolist())\n",
    "print(\"y (타겟) 데이터 미리보기 (첫 5개):\", y.head().tolist())\n",
    "\n",
    "# 2.2 훈련 세트와 테스트 세트로 데이터 분할 (80% 훈련, 20% 테스트)\n",
    "# random_state는 나중에 다시 실행해도 같은 결과가 나오도록 고정하는 숫자입니다.\n",
    "# stratify=y는 타겟(y)의 비율을 훈련/테스트 세트에 동일하게 맞춰주는 중요한 옵션입니다.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\n데이터 분할 완료.\")\n",
    "print(f\"훈련 데이터 X_train 크기 : {X_train.shape}\") # (행 개수, 열 개수)\n",
    "print(f\"예측 데이터 X_test 크기 : {X_test.shape}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9649e5",
   "metadata": {},
   "source": [
    "\n",
    "### 이 코드의 의미 (간결하게)\n",
    "\n",
    "  * **`X = df[['sepal_length', ...]]`**: 예측에 사용할 입력 정보들(꽃받침/꽃잎 길이와 너비)을 `X`라는 변수에 담습니다. **대괄호 두 개**는 여러 컬럼을 선택한다는 뜻이에요.\n",
    "  * **`y = df['species_encoded']`**: 예측하려는 결과값(붓꽃 종류)을 `y`라는 변수에 담습니다. 우리는 앞서 숫자로 변환한 `species_encoded` 컬럼을 사용할 거예요.\n",
    "  * **`train_test_split(X, y, ...)`**: 이 함수가 `X`와 `y` 데이터를 '훈련용'과 '테스트용'으로 싹둑 잘라줍니다.\n",
    "      * `test_size=0.2`: 전체 데이터 중 20%를 테스트용으로, 80%를 훈련용으로 사용하겠다는 의미.\n",
    "      * `random_state=42`: 데이터를 나눌 때 무작위로 나누는데, 이 숫자를 고정하면 나중에 다시 실행해도 **항상 똑같은 방식으로** 데이터가 나뉘게 됩니다. (결과 재현 가능하게 함)\n",
    "      * `stratify=y`: `y` (붓꽃 종류)의 비율을 훈련 세트와 테스트 세트가 **거의 동일하게** 가지도록 해줍니다. 예를 들어, 전체 데이터에 setosa, versicolor, virginica가 각각 1/3씩 있다면, 훈련 세트와 테스트 세트에도 이 비율이 거의 유지되도록 나눕니다. (분류 문제에서 매우 중요\\!)\n",
    "  * **`X_train`, `X_test`, `y_train`, `y_test`**: `train_test_split`의 결과로 나오는 네 개의 데이터 덩어리입니다.\n",
    "      * `X_train`, `y_train`: 모델을 **훈련**시킬 때 사용.\n",
    "      * `X_test`, `y_test`: 모델이 훈련된 후 **성능을 테스트**할 때 사용.\n",
    "  * **`.shape`**: 데이터의 '모양' 또는 '크기'를 보여줍니다. (행 개수, 열 개수)\n",
    "\n",
    "\n",
    "X.columns.tolist()는 \"특성 데이터 X에 들어있는 모든 컬럼(열)들의 이름을 뽑아서, 파이썬 리스트 형태로 보여줘!\" 라는 뜻입니다.\n",
    "y.head().tolist()는 \"타겟 데이터 y의 맨 위 5개 값을 뽑아서, 파이썬 리스트 형태로 보여줘!\" 라는 뜻입니다.\n",
    "\n",
    "두 함수 모두 데이터가 어떻게 분리되었고, 어떤 값들을 포함하고 있는지를 확인하는 용도로 사용됩니다. \n",
    "특히 tolist()는 Pandas 객체를 파이썬 기본 리스트 형태로 변환하여 출력이나 추가적인 처리에 편리하게 사용할 수 있도록 해줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0e610",
   "metadata": {},
   "source": [
    "[목표] Iris (붓꽃) 데이터셋으로 '붓꽃의 종류' 예측하기\n",
    "단계 3: 모델 학습 및 예측\n",
    "여기서는 KNeighborsClassifier 모델을 사용해서 붓꽃 데이터를 학습시키고, 학습된 모델로 테스트 데이터의 붓꽃 종류를 예측할 거예요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "158229a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 생성 완료 : KNeighborsClassifier()\n",
      "모델 학습 완료.\n",
      "\n",
      "모델 예측 완료.\n",
      "예측된 타겟 값 미리보기 (첫 5개): [0, 2, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# 3.1 모델 선택 및 생성 (K-최근접 이웃 분류기)\n",
    "# n_neighbors=5는 가장 가까운 5개의 이웃을 참고해서 예측하라는 의미입니다.\n",
    "# random_state=42는 모델 내부의 무작위성을 고정하여 결과를 재현 가능하게 합니다.\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "print(f\"모델 생성 완료 : {model}\")\n",
    "\n",
    "# 3.2 모델 학습 (훈련 데이터 사용)\n",
    "# X_train(특성)과 y_train(타겟)을 사용하여 모델을 훈련시킵니다.\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"모델 학습 완료.\")\n",
    "\n",
    "# 3.3 모델 예측 (테스트 데이터 사용)\n",
    "# 학습된 모델로 X_test(테스트 특성)에 대한 y_pred(예측값)를 만듭니다.\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\n모델 예측 완료.\")\n",
    "print(\"예측된 타겟 값 미리보기 (첫 5개):\", y_pred[:5].tolist()) # 예측값의 처음 5개만 리스트로 보기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e75349",
   "metadata": {},
   "source": [
    "### 이 코드의 의미 (간결하게)\n",
    "\n",
    "  * **`model = KNeighborsClassifier(n_neighbors=5)`**:\n",
    "      * `KNeighborsClassifier`: **K-최근접 이웃 분류기**라는 머신러닝 모델을 사용하겠다고 선언하는 부분입니다. (이름이 길지만, '제일 비슷한 이웃들을 보고 결정하는 모델'이라고 생각하세요.)\n",
    "      * `n_neighbors=5`: 이 모델이 예측할 때 **가장 가까운 5개의 붓꽃 정보**를 참고하라는 설정입니다. (이 숫자가 모델의 성능에 영향을 줄 수 있어요.)\n",
    "      * `model`: 이렇게 만들어진 K-최근접 이웃 분류기 '도구'에 `model`이라는 이름을 붙여 변수에 담습니다.\n",
    "  * **`model.fit(X_train, y_train)`**:\n",
    "      * `model`: 위에서 준비한 K-최근접 이웃 분류기 도구입니다.\n",
    "      * `.fit(...)`: 이 도구에게 **'학습해\\!'** 라고 명령하는 함수입니다.\n",
    "      * `X_train`: 훈련시킬 때 사용할 붓꽃의 특징들(꽃받침/꽃잎 길이, 너비)입니다.\n",
    "      * `y_train`: 훈련시킬 때 사용할 각 붓꽃의 '정답' (종류)입니다.\n",
    "      * **결론:** `X_train`과 `y_train` 데이터를 가지고 `model`을 **훈련**시키는 과정입니다. 모델은 이 데이터를 보고 붓꽃의 특징과 종류 사이의 관계를 학습합니다.\n",
    "  * **`y_pred = model.predict(X_test)`**:\n",
    "      * `model`: 학습이 완료된 붓꽃 분류 도구입니다.\n",
    "      * `.predict(...)`: 이 도구에게 **'예측해\\!'** 라고 명령하는 함수입니다.\n",
    "      * `X_test`: **모델이 한 번도 보지 못했던 새로운 붓꽃의 특징들** (테스트 데이터)입니다.\n",
    "      * `y_pred`: `predict` 함수가 예측한 붓꽃 종류(숫자)들이 담길 변수입니다.\n",
    "      * **결론:** 학습된 모델에게 `X_test` 데이터를 주고, 이 붓꽃들이 각각 어떤 종류일지 **예측하도록 하는** 과정입니다. 예측 결과는 `y_pred`에 저장됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc4be18",
   "metadata": {},
   "source": [
    "이제 대망의 마지막 단계인 모델 평가를 진행해 봅시다. 모델이 예측한 결과(y_pred)가 실제 정답(y_test)과 얼마나 일치하는지 확인해야 해요.\n",
    "\n",
    "[목표] Iris (붓꽃) 데이터셋으로 '붓꽃의 종류' 예측하기\n",
    "단계 4: 모델 평가 (정확도)\n",
    "우리가 예측한 결과와 실제 정답을 비교하여 **정확도(Accuracy)**를 계산할 거예요. 정확도는 모델이 전체 테스트 데이터 중에서 몇 퍼센트를 맞혔는지를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28770bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "모델의 정확도: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 4.1 모델 평가 (정확도 계산)\n",
    "# sklearn.metrics 모듈에서 accuracy_score 함수를 불러옵니다.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# y_test(실제 정답)와 y_pred(모델 예측값)를 비교하여 정확도를 계산합니다.\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n모델의 정확도: {accuracy:.4f}\") # 소수점 4자리까지 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4379efc",
   "metadata": {},
   "source": [
    "코드의 의미 (간결하게)\n",
    "\n",
    "from sklearn.metrics import accuracy_score: 모델 성능을 평가하는 \n",
    "다양한 도구들이 모여있는 sklearn.metrics라는 곳에서, \n",
    "그중 accuracy_score라는 **'정확도 계산 도구'**를 불러오는 코드입니다.\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred):\n",
    "\n",
    "불러온 accuracy_score 도구에게 **'실제 정답(y_test)'**과 **'모델의 예측값(y_pred)'**을 주면서 정확도를 계산해달라고 명령합니다.\n",
    "\n",
    "계산된 정확도 결과는 accuracy라는 변수에 저장됩니다.\n",
    "\n",
    "print(f\"모델의 정확도: {accuracy:.4f}\"): 계산된 accuracy 값을 화면에 보여줍니다. :.4f는 소수점 아래 넷째 자리까지 표시하라는 의미예요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0eb47404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 데이터 로드 완료 ---\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "\n",
      "--- 2.1 결측치 처리 (생략: Iris 데이터셋은 결측치 없음) ---\n",
      "\n",
      "--- 2.2 'species' 컬럼 인코딩 완료 ---\n",
      "변환된 타겟 클래스 매핑: [('setosa', np.int64(0)), ('versicolor', np.int64(1)), ('virginica', np.int64(2))]\n",
      "  species  species_encoded\n",
      "0  setosa                0\n",
      "1  setosa                0\n",
      "2  setosa                0\n",
      "3  setosa                0\n",
      "4  setosa                0\n",
      "\n",
      "--- 3. 특성(X)과 타겟(y) 분리 완료 ---\n",
      "X (특성) 컬럼: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "y (타겟) 미리보기: [0, 0, 0, 0, 0]\n",
      "\n",
      "--- 4. 데이터 분할 완료 ---\n",
      "훈련 데이터 X_train 크기: (120, 4)\n",
      "테스트 데이터 X_test 크기: (30, 4)\n",
      "\n",
      "--- 5.1 모델 생성 완료: KNeighborsClassifier() ---\n",
      "--- 5.2 모델 학습 완료 ---\n",
      "\n",
      "--- 6. 모델 예측 완료 ---\n",
      "예측된 타겟 값 미리보기 (첫 5개): [0, 2, 1, 1, 0]\n",
      "\n",
      "--- 7. 모델 평가 (정확도) 완료 ---\n",
      "모델의 정확도: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#오늘 Iris 데이터셋으로 머신러닝의 핵심 7단계를 직접 경험하며 사용했던 코드들을 요청하신 대로 한데 모아 정리해 드릴게요. \n",
    "#이 코드들은 앞으로 다른 데이터셋에 적용할 때도 '수학 공식'처럼 활용할 수 있는 기본 템플릿이 될 거예요.\n",
    "\n",
    "#[ Iris (붓꽃) 분류 모델 기본 코드 ]\n",
    "\n",
    "# 필요한 라이브러리 불러오기\n",
    "import pandas as pd # 데이터프레임 다루는 데 사용\n",
    "import seaborn as sns # 예제 데이터셋 불러오는 데 사용 (iris)\n",
    "from sklearn.model_selection import train_test_split # 데이터 분할\n",
    "from sklearn.preprocessing import LabelEncoder # 범주형 데이터를 숫자로 변환\n",
    "from sklearn.neighbors import KNeighborsClassifier # K-최근접 이웃 분류 모델\n",
    "from sklearn.metrics import accuracy_score # 모델 성능 평가 (정확도)\n",
    "\n",
    "# --- 1. 데이터 로드 ---\n",
    "# seaborn 내장 iris 데이터셋 불러오기\n",
    "df = sns.load_dataset('iris')\n",
    "print(\"--- 1. 데이터 로드 완료 ---\")\n",
    "print(df.head())\n",
    "print(df.info()) # 데이터 정보 확인\n",
    "\n",
    "# --- 2. 결측치 처리 및 범주형 인코딩 ---\n",
    "# 2.1 결측치 처리 (iris 데이터셋은 결측치가 없어 생략)\n",
    "print(\"\\n--- 2.1 결측치 처리 (생략: Iris 데이터셋은 결측치 없음) ---\")\n",
    "\n",
    "# 2.2 범주형 특성 인코딩 (타겟 'species' 컬럼을 숫자로 변환)\n",
    "le_species = LabelEncoder()\n",
    "df['species_encoded'] = le_species.fit_transform(df['species'])\n",
    "print(\"\\n--- 2.2 'species' 컬럼 인코딩 완료 ---\")\n",
    "print(\"변환된 타겟 클래스 매핑:\", list(zip(le_species.classes_, le_species.transform(le_species.classes_))))\n",
    "print(df[['species', 'species_encoded']].head())\n",
    "\n",
    "# --- 3. 특성(X)과 타겟(y) 분리 ---\n",
    "# X (특성): 예측에 사용할 입력 컬럼들\n",
    "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "# y (타겟): 예측하려는 결과 컬럼 (숫자로 인코딩된 'species_encoded' 사용)\n",
    "y = df['species_encoded']\n",
    "print(\"\\n--- 3. 특성(X)과 타겟(y) 분리 완료 ---\")\n",
    "print(\"X (특성) 컬럼:\", X.columns.tolist())\n",
    "print(\"y (타겟) 미리보기:\", y.head().tolist())\n",
    "\n",
    "\n",
    "# --- 4. 데이터 분할 (훈련/테스트 세트) ---\n",
    "# X, y 데이터를 훈련용(80%)과 테스트용(20%)으로 분할\n",
    "# random_state=42: 매번 동일하게 데이터가 분할되도록 고정\n",
    "# stratify=y: y(타겟)의 클래스 비율을 훈련/테스트 세트가 동일하게 가지도록 유지 (분류 문제에 중요)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"\\n--- 4. 데이터 분할 완료 ---\")\n",
    "print(f\"훈련 데이터 X_train 크기: {X_train.shape}\")\n",
    "print(f\"테스트 데이터 X_test 크기: {X_test.shape}\")\n",
    "\n",
    "\n",
    "# --- 5. 모델 선택 및 학습 ---\n",
    "# K-최근접 이웃 분류기(KNeighborsClassifier) 모델 선택\n",
    "# n_neighbors=5: 가장 가까운 5개의 이웃을 참고하여 예측\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "print(f\"\\n--- 5.1 모델 생성 완료: {model} ---\")\n",
    "\n",
    "# 훈련 데이터(X_train, y_train)로 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "print(\"--- 5.2 모델 학습 완료 ---\")\n",
    "\n",
    "\n",
    "# --- 6. 모델 예측 ---\n",
    "# 학습된 모델로 테스트 데이터(X_test)에 대한 예측 수행\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n--- 6. 모델 예측 완료 ---\")\n",
    "print(\"예측된 타겟 값 미리보기 (첫 5개):\", y_pred[:5].tolist())\n",
    "\n",
    "\n",
    "# --- 7. 모델 평가 ---\n",
    "# 실제 정답(y_test)과 모델 예측값(y_pred)을 비교하여 정확도 계산\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n--- 7. 모델 평가 (정확도) 완료 ---\")\n",
    "print(f\"모델의 정확도: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35dbde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl250801",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
